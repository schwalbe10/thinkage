---
layout: post
title: "Deep Learning 6 - Calculate a value of the loss function"
date:  2017-05-25

tags:
- AI
- Deep Learning
- Python
---

From this post, we'll challenge learning process of neural network. The learning step is as follows;

1. Divide a dataset into training data and test data
1. Select part of training data (mini-batch) randomly
1. Calculate the gradient to reduce the value of the loss function
1. Update weights with the gradient
1. Iterate step 2, 3, and 4

Before you implement them, you need to understand a loss function. It shows inaccuracy of neural networks. This procedure is the way to find parameters whose loss function will be minimal.

One of useful loss functions is cross-entropy error that is represented by;

$$
\begin{equation}
    E = - \sum_k t_k \log_e y_k
\end{equation}
$$

Where $$ y_k $$ is an output of neural network and $$ t_k $$ is an answer label with a one-hot array (e.g. 7 -> [0,0,0,0,0,0,0,1,0,0]). It calculates the natural logarithm for the output related to the answer. As the output with the answer increase, the loss function gets closer to 0.

![loss]({{site.github.url}}/images/posts/loss.png)

We've considered the loss function of one data. When you calculate the sum of $$ N $$ data, the equation is simply transformed to;

$$
\begin{equation}
    E = - \frac{1}{N} \sum_n \sum_k t_{nk} \log_e y_{nk}
\end{equation}
$$

However, it takes a lot of time to calculate it in practice. We usually handle it with a mini-batch that is randomly selected in the dataset.

<div class="filename"><span class="t">06_loss.py</span></div>
``` python
# Display all arrays
# np.set_printoptions(threshold=np.inf)

# Generate a mini-batch
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)
train_size = x_train.shape[0]
batch_size = 3
batch_mask = np.random.choice(train_size, batch_size)
print(x_train[batch_mask])
print(t_train[batch_mask])
```

The result is here (If you want to see the all arrays, please insert *np.set_printoptions*);

``` python
[[ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]]
[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]
 [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]
```

The following code is to calculate a value of the loss function with an answer label (not a one-hot array) when the outputs are bundled by mini-batch.

<div class="filename"><span class="t">functions.py</span></div>
``` python
def cross_entropy_error(y, t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    # If t is a one-hot array, transform it into the answer label
    if t.size == y.size:
        t = t.argmax(axis=1)

    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size
```

If you understand the loss function with a mini-batch, let's go to the next step about the gradient!

*The sample code is [here](https://github.com/schwalbe10/ThinkageDeepLearning).*

### Reference

<div class="list">
  <ul>
    <li><a href="https://www.amazon.co.jp/gp/product/4873117585/ref=as_li_tf_tl?ie=UTF8&camp=247&creative=1211&creativeASIN=4873117585&linkCode=as2&tag=schwalbe0d-22">Deep Learning From Scratch (Japanese)</a></li>
  </ul>
</div>
